-- glslfx version 0.1

//
// Copyright 2019 Pixar
//
// Licensed under the Apache License, Version 2.0 (the "Apache License")
// with the following modification; you may not use this file except in
// compliance with the Apache License and the following modification to it:
// Section 6. Trademarks. is deleted and replaced with:
//
// 6. Trademarks. This License does not grant permission to use the trade
//    names, trademarks, service marks, or product names of the Licensor
//    and its affiliates, except as required to comply with Section 4(c) of
//    the License and to reproduce the content of the NOTICE file.
//
// You may obtain a copy of the Apache License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the Apache License with the above modification is
// distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied. See the Apache License for the specific
// language governing permissions and limitations under the Apache License.
//

-- configuration
{
    "techniques": {
        "default": {
            "domeLightIrradiance": {
                "source": [ "DomeLight.Irradiance"]
            },
            "domeLightPrefilter": {
                "source": [ "DomeLight.Prefilter"]
            },
            "domeLightBRDF": {
                "source": [ "DomeLight.BRDF"]
            }
        }
    }
}

--- --------------------------------------------------------------------------
-- glsl DomeLight.Irradiance

layout(local_size_x = 32, local_size_y = 32) in;
layout(binding = 0) uniform sampler2D inTexture;
layout(rgba16f, binding = 1) uniform image2D outTexture;

const float PI = 3.14159265359;
const float sampleDelta = 0.025;

vec3 SampleMap(vec3 sampleVec) {
    // transform sample vector into 2D coordinate (normalized)
    vec2 fragCoord = vec2((atan(sampleVec.x, sampleVec.y) + PI) / (2.0*PI),
                        acos(sampleVec.z) / PI);

    // sample from a mipmap level of the environment map determined by the 
    // size of the environment map and the number of samples we are taking
    ivec2 inDims = textureSize(inTexture, 0);
    int mipLevel = int(ceil(log2(inDims.x * sampleDelta/(2.0 * PI)) * 2.0f));
    inDims = textureSize(inTexture, mipLevel);

    return textureLod(inTexture, fragCoord, mipLevel).rgb;
}
vec3 GetWorldPos(vec2 textureCoord) {
    // have theta range from [-PI, PI] so the origin is in the center
    // of the image
    float theta = (textureCoord.x * 2.0 * PI) - PI;
    float phi = (textureCoord.y * PI);
    float x = cos(theta) * sin(phi);
    float y = sin(theta) * sin(phi);
    float z = cos(phi);
    // flipping to match the wrapping of the texture
    return vec3(y, x, -z); 
}
vec2 GetFragCoords(ivec2 pixelCoords) {
    vec2 inDims = imageSize(outTexture);
    // vec2 inDims = textureSize(inTexture, 0);
    vec2 fragCoords = (pixelCoords / inDims);

    // y axis is flipped between texture and pixel coordinates
    fragCoords.y = 1.0 - fragCoords.y;
    return fragCoords;
}
ivec2 GetPixelCoords(vec2 fragCoords) {
    ivec2 outDims = imageSize(outTexture); 

    // y axis is flipped between texture and pixel coordinates
    fragCoords.y = 1.0f - fragCoords.y;
        
    vec2 outCoords = fragCoords * outDims;
    outCoords.y = outCoords.y + 0.5f;
    return ivec2(ceil(outCoords));
}

void main(void) 
{
    // pixel coords needs to be transformed into fragment coords on the 
    // environment map, and then into a 3D world position on the sphere 
    // representation on the environment map. Then use that world position 
    // as a normal to then sample the hemisphere centered about that normal 
    ivec2 pixelCoords = ivec2(gl_GlobalInvocationID.xy);
    vec2 fragCoords = GetFragCoords(pixelCoords);
    vec3 pos3D = GetWorldPos(fragCoords);
    vec3 N = normalize(pos3D);

    // Irradiance Convolution 
    vec3 irradiance = vec3(0.0);
    // create basis for transforming from tangent space to world space
    vec3 up = vec3(0.0, 0.0, 1.0);
    vec3 right = cross(up, N);
    up = cross(N, right);

    // sample the hemisphere centered at the normal N 
    float sampleDelta = 0.025;
    float nrSamples = 0.0;
    for (float theta = 0; theta < 2.0*PI; theta += sampleDelta) {
        for (float phi = 0.0; phi < 0.5 * PI; phi += sampleDelta) {

            // transform sample into tangent space 
            vec3 tangentSample = vec3( cos(theta) * sin(phi),
                                       cos(phi),
                                       sin(theta) * sin(phi) );
            // use the basis to transform the tangentSample into World space
            vec3 sampleVec = tangentSample.x * right +
                             tangentSample.y * N +
                             tangentSample.z * up; 

            // use that world space coordinate to sample the environment map
            irradiance += SampleMap(sampleVec) * cos(phi) * sin(phi);
            nrSamples++;
        }
    }
    irradiance = PI * irradiance * (1.0 / float(nrSamples));
    vec4 newPixelColor = vec4(irradiance, 1.0);

    // output new color to a specific pixel in the output image
    ivec2 outPixels = GetPixelCoords(fragCoords);
    imageStore(outTexture, outPixels, newPixelColor);
}

--- --------------------------------------------------------------------------
-- glsl DomeLight.Prefilter

layout(local_size_x = 32, local_size_y = 32) in;
layout(binding = 0) uniform sampler2D inTexture;
layout(rgba16f, binding = 1) uniform image2D outTexture;
uniform float roughness; 

const float PI = 3.14159265359;

vec3 SampleMap(vec3 sampleVec, int sampleLevel) {
    // translate the sampleVec into pixel coordinates
    ivec2 inDims = textureSize(inTexture, sampleLevel);
    vec2 coord = vec2(atan(sampleVec.z, sampleVec.x) / (2.0 * PI),
                        asin(sampleVec.y) / PI);
    coord += 0.5f;
    ivec2 pixelCoord = ivec2(ceil(coord * inDims));

    // return the color of the environment map at the calculated pixel
    // location and the desired mip level 
    // return texelFetch(inTexture, pixelCoord, sampleLevel).rgb;
    return textureLod(inTexture, coord, sampleLevel).rgb;
}
vec3 GetWorldPos(vec2 textureCoord) {
    // have theta range from [-PI, PI] so the origin is in the center
    // of the image
    float theta = (textureCoord.x * 2.0 * PI) - PI;
    float phi = (textureCoord.y * PI);
    float x = cos(theta) * sin(phi);
    float y = cos(phi);
    float z = sin(theta) * sin(phi);
    return vec3(x, y, z);
}
vec2 GetFragCoords(ivec2 pixelCoords) {
    // get the dimensions from the full enviornment map 
    vec2 inDims = textureSize(inTexture, 0);
    vec2 fragCoords = (pixelCoords / inDims);
    
    // y axis is flipped between texture and pixel coordinates
    fragCoords.y = 1.0 - fragCoords.y;
    
    return fragCoords;
}
ivec2 GetPixelCoords(vec2 fragCoords) {
    ivec2 outDims = imageSize(outTexture);

    // y axis is flipped between texture and pixel coordinates
    fragCoords.y = 1.0 - fragCoords.y;

    vec2 outCoords = fragCoords * outDims;
    // for some reason needed this to eliminate lines in the final texture
    outCoords.y += 0.5f;    
    return ivec2(ceil(outCoords));
}
float GetInTextureResolution() {
    ivec2 inDims = textureSize(inTexture, 0);
    return (inDims.x* inDims.y);
}

float DistributionGGX(vec3 N, vec3 H, float roughness) {
    float a = roughness*roughness;
    float a2 = a*a;
    float NdotH = max(dot(N, H), 0.0);
    float NdotH2 = NdotH*NdotH;
    float nom = a2;
    float denom = (NdotH2 * (a2 - 1.0) + 1.0);
    denom = PI * denom * denom;
    return nom / denom;
}
// http://holger.dammertz.org/stuff/notes_HammersleyOnHemisphere.html
// efficient VanDerCorpus calculation.
float RadicalInverse_VdC(uint bits) {
    bits = (bits << 16u) | (bits >> 16u);
    bits = ((bits & 0x55555555u) << 1u) | ((bits & 0xAAAAAAAAu) >> 1u);
    bits = ((bits & 0x33333333u) << 2u) | ((bits & 0xCCCCCCCCu) >> 2u);
    bits = ((bits & 0x0F0F0F0Fu) << 4u) | ((bits & 0xF0F0F0F0u) >> 4u);
    bits = ((bits & 0x00FF00FFu) << 8u) | ((bits & 0xFF00FF00u) >> 8u);
    return float(bits) * 2.3283064365386963e-10; // / 0x100000000
}
vec2 Hammersley(uint i, uint N) {
    return vec2(float(i) / float(N), RadicalInverse_VdC(i));
}
vec3 ImportanceSampleGGX(vec2 Xi, vec3 N, float roughness) {
    float a = roughness*roughness;
    float phi = 2.0 * PI * Xi.x;
    float cosTheta = sqrt((1.0 - Xi.y) / (1.0 + (a*a - 1.0) * Xi.y));
    float sinTheta = sqrt(1.0 - cosTheta*cosTheta);

    // from spherical coordinates to cartesian coordinates - halfway vector
    vec3 H;
    H.x = cos(phi) * sinTheta;
    H.y = sin(phi) * sinTheta;
    H.z = cosTheta;
    
    // from tangent-space H vector to world-space sample vector
    vec3 up = abs(N.z) < 0.999 ? vec3(0.0, 0.0, 1.0) : vec3(1.0, 0.0, 0.0);
    vec3 tangent = normalize(cross(up, N));
    vec3 bitangent = cross(N, tangent);
    vec3 sampleVec = tangent * H.x + bitangent * H.y + N * H.z;
    return normalize(sampleVec);
}

void main(void)
{
    // pixel coords needs to be transformed into fragment coords on the 
    // environment map, and then into a 3D world position on the sphere 
    // representation on the environment map. Then use that world position 
    // as a normal to then sample the hemisphere centered about that normal 
    ivec2 pixelCoords = ivec2(gl_GlobalInvocationID.xy);
    vec2 fragCoords = GetFragCoords(pixelCoords);
    vec3 pos3D = GetWorldPos(fragCoords);
    vec3 N = normalize(pos3D);

    // make the simplyfying assumption that V equals R equals the normal 
    vec3 R = N;
    vec3 V = R;

    // Importance Sampling 
    const uint SAMPLE_COUNT = 1024u;
    vec3 prefilteredColor = vec3(0.0);
    float totalWeight = 0.0;
    for (uint i = 0u; i < SAMPLE_COUNT; ++i) {
        // generates a sample vector that's biased towards the preferred
        // alignment direction ie. sampling about the specular lobe
        vec2 Xi = Hammersley(i, SAMPLE_COUNT);
        vec3 H = ImportanceSampleGGX(Xi, N, roughness);
        vec3 L = normalize(2.0 * dot(V, H) * H - V);
        float NdotL = max(dot(N, L), 0.0);

        if (NdotL > 0.0) {
            // sample the environment map at a mip level based on the 
            // roughness/pdf
            float D = DistributionGGX(N, H, roughness);
            float NdotH = max(dot(N, H), 0.0);
            float HdotV = max(dot(H, V), 0.0);
            float pdf = D * NdotH / (4.0 * HdotV) + 0.0001;

            // calculate the mip-level
            float resolution = GetInTextureResolution(); 
            float saTexel = 4.0 * PI / resolution;
            float saSample = 1.0 / (float(SAMPLE_COUNT) * pdf + 0.0001);
            float mipLevel = roughness == 0.0 ? 0.0 :
                                                0.5 * log2(saSample / saTexel);  

            // Sample the environment map at the calculated mip level
            prefilteredColor += SampleMap(L, int(mipLevel)) * NdotL;
            totalWeight += NdotL;
        }
    }
    prefilteredColor = prefilteredColor / totalWeight;
    vec4 newPixelColor = vec4(prefilteredColor, 1.0);

    // output new color to a specific pixel in the output image 
    ivec2 outPixels = GetPixelCoords(fragCoords);
    imageStore(outTexture, outPixels, newPixelColor);	
}

--- --------------------------------------------------------------------------
-- glsl DomeLight.BRDF

layout(local_size_x = 32, local_size_y = 32) in;
layout(binding = 0) uniform sampler2D inTexture;
layout(rgba16f, binding = 1) uniform image2D outTexture;
uniform int sampleLevel = 0;

const float PI = 3.14159265359;

vec2 GetFragCoords(ivec2 pixelCoords) {
    vec2 inDims = textureSize(inTexture, sampleLevel);
    vec2 fragCoords = (pixelCoords / inDims);
    return fragCoords;
}
ivec2 GetPixelCoords(vec2 fragCoords) {
    ivec2 outDims = imageSize(outTexture);
    vec2 outCoords = fragCoords * outDims;
    return ivec2(ceil(outCoords));
}

float RadicalInverse_VdC(uint bits) {
    bits = (bits << 16u) | (bits >> 16u);
    bits = ((bits & 0x55555555u) << 1u) | ((bits & 0xAAAAAAAAu) >> 1u);
    bits = ((bits & 0x33333333u) << 2u) | ((bits & 0xCCCCCCCCu) >> 2u);
    bits = ((bits & 0x0F0F0F0Fu) << 4u) | ((bits & 0xF0F0F0F0u) >> 4u);
    bits = ((bits & 0x00FF00FFu) << 8u) | ((bits & 0xFF00FF00u) >> 8u);
    return float(bits) * 2.3283064365386963e-10; // / 0x100000000
}
vec2 Hammersley(uint i, uint N) {
    return vec2(float(i) / float(N), RadicalInverse_VdC(i));
}
vec3 ImportanceSampleGGX(vec2 Xi, vec3 N, float roughness) {
    float a = roughness*roughness;
    float phi = 2.0 * PI * Xi.x;
    float cosTheta = sqrt((1.0 - Xi.y) / (1.0 + (a*a - 1.0) * Xi.y));
    float sinTheta = sqrt(1.0 - cosTheta*cosTheta);
    
    // from spherical coordinates to cartesian coordinates - halfway vector
    vec3 H;
    H.x = cos(phi) * sinTheta;
    H.y = sin(phi) * sinTheta;
    H.z = cosTheta;
    
    // from tangent-space H vector to world-space sample vector
    vec3 up = abs(N.z) < 0.999 ? vec3(0.0, 0.0, 1.0) : vec3(1.0, 0.0, 0.0);
    vec3 tangent = normalize(cross(up, N));
    vec3 bitangent = cross(N, tangent);
    vec3 sampleVec = tangent * H.x + bitangent * H.y + N * H.z;
    return normalize(sampleVec);
}

float GeometrySchlickGGX(float NdotV, float roughness) {
    // note that we use a different k for IBL
    float a = roughness;
    float k = (a * a) / 2.0;
    float nom   = NdotV;
    float denom = NdotV * (1.0 - k) + k;
    return nom / denom;
}
float GeometrySmith(vec3 N, vec3 V, vec3 L, float roughness) {
    float NdotV = max(dot(N, V), 0.0);
    float NdotL = max(dot(N, L), 0.0);
    float ggx2 = GeometrySchlickGGX(NdotV, roughness);
    float ggx1 = GeometrySchlickGGX(NdotL, roughness);
    return ggx1 * ggx2;
}

// using the Split-Sum approach to integrate the BRDF
vec2 IntegrateBRDF(float NdotV, float roughness) {
    vec3 V;
    V.x = sqrt(1.0 - NdotV*NdotV);
    V.y = 0.0;
    V.z = NdotV;

    // calculate the scale bias terms
    float scale = 0.0;
    float bias = 0.0; 
    vec3 N = vec3(0.0, 0.0, 1.0);

    const uint SAMPLE_COUNT = 1024u;
    for(uint i = 0u; i < SAMPLE_COUNT; ++i) {
        // generate a sample vector that's biased towards the preferred 
        // alignment direction ie. the specular lobe
        vec2 Xi = Hammersley(i, SAMPLE_COUNT);
        vec3 H = ImportanceSampleGGX(Xi, N, roughness);
        vec3 L = normalize(2.0 * dot(V, H) * H - V);
        float NdotL = max(L.z, 0.0);
        float NdotH = max(H.z, 0.0);
        float VdotH = max(dot(V, H), 0.0);

        if(NdotL > 0.0) {
            float G = GeometrySmith(N, V, L, roughness);
            float G_Vis = (G * VdotH) / (NdotH * NdotV);
            float Fc = pow(1.0 - VdotH, 5.0);

            scale += (1.0 - Fc) * G_Vis;
            bias += Fc * G_Vis;
        }
    }
    scale /= float(SAMPLE_COUNT);
    bias /= float(SAMPLE_COUNT);
    return vec2(scale, bias);
}

void main(void) 
{
    // transfor pixel coords into fragment coords 
    ivec2 pixelCoords = ivec2(gl_GlobalInvocationID.xy);
    vec2 fragCoords = GetFragCoords(pixelCoords);

    // compute the BRDF based on the fragCoords
    // fragCoords.x represents NdotE and fragCoords.y represents roughness
    vec2 integratedBRDF = IntegrateBRDF(fragCoords.x, fragCoords.y);
    vec4 newPixelColor = vec4(integratedBRDF, 0.0, 1.0);

    // output to a specific pixel in the image 
    ivec2 outPixels = GetPixelCoords(fragCoords);
    imageStore(outTexture, outPixels, newPixelColor);
}